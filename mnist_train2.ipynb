{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8256ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import tensorwatch as tw\n",
    "from torchvision import models\n",
    "from torchsummary import summary  #输出网络模型结构的相关包\n",
    "from matplotlib import pyplot as plt # 导入matplotlib库，用于绘图\n",
    "\n",
    "from utils import plot_image,plot_curve,one_hot # 导入自定义的一些工具函数，如plot_image, plot_curve, one_hot\n",
    "\n",
    "import os  # 导入os库，用于操作系统相关的功能\n",
    "\n",
    "os.environ[\n",
    "    'KMP_DUPLICATE_LIB_OK']='TRUE'   # 设置一个环境变量，防止出现重复的库的错误\n",
    "\n",
    "# import torch.onnx\n",
    "\n",
    "batch_size=512  # 设置每个批次的数据量为512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb0569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试下GPU版本的pytorch是否安装成功\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f93bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个训练数据加载器，使用torchvision.datasets.MNIST方法下载并加载MNIST手写数字数据集\n",
    "# 使用torchvision.transforms.Compose方法对数据进行预处理，包括转换为张量和归一化\n",
    "# 使用torch.utils.data.DataLoader方法将数据封装成批次，并打乱顺序\n",
    "train_loader=torch.utils.data.DataLoader(\n",
    "    \n",
    "    torchvision.datasets.MNIST('mnist_data',train=True,download=True,\n",
    "                               transform=torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.ToTensor(),\n",
    "                                   torchvision.transforms.Normalize(\n",
    "                                       (0.1307,),(0.3081,))\n",
    "                               ])),\n",
    "    batch_size=batch_size,shuffle=True)\n",
    "\n",
    "test_loader=torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('mnist_data/',train=False,download=True,\n",
    "                               transform=torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.ToTensor(),\n",
    "                                   torchvision.transforms.Normalize(\n",
    "                                       (0.1307,),(0.3081,))\n",
    "                               ])),\n",
    "    batch_size=batch_size,shuffle=False)\n",
    "\n",
    "x,y=next(iter(train_loader))  # 使用next(iter())方法从训练数据加载器中获取下一个批次的数据，包括输入x和标签y\n",
    "print(x.shape,y.shape,x.min(),x.max())  # 打印x和y的形状、x的最小值和最大值\n",
    "\n",
    "plot_image(x,y,'image sample')\n",
    "\n",
    "# 移动到GPU上\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # （自己添加）\n",
    "x=x.to(device)  # （自己添加）\n",
    "y=y.to(device)  # （自己添加）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "# 定义神经网络模型类Net继承nn.Module类\n",
    "\n",
    "    def __init__(self):\n",
    "    # 定义模型的初始化方法\n",
    "\n",
    "        super(Net,self).__init__()\n",
    "        # 继承并执行父类（nn.Module）的初始化方法\n",
    "        # xw+b\n",
    "        self.fc1=nn.Linear(28 * 28,256)\n",
    "        # 第一层全连接层，输入特征向量28*28，输出特征向量256\n",
    "        self.fc2=nn.Linear(256,64)\n",
    "        # 第二层全连接层，输入特征向量256，输出特征向量64\n",
    "        self.fc3=nn.Linear(64,10)\n",
    "        # 第三层全连接层，输入特征向量64，输出特征向量10\n",
    "\n",
    "    def forward(self,x):\n",
    "    # 定义前向传播计算过程的方法forward，输入参数x是模型输入\n",
    "\n",
    "        # x: [b, 1, 28, 28]\n",
    "        # h1 = relu(xw1+b1)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        # 将第一层的输出传递到第二层，并应用ReLU激活函数 进行非线性变换\n",
    "        # h2 = relu(h1w2+b2)\n",
    "        x=F.relu(self.fc2(x))\n",
    "        # h1作为输入通过第二层全连接层计算得到h2，并应用激活函数relu进行非线性变换\n",
    "        # h3 = h2w3+b3\n",
    "        x=self.fc3(x)\n",
    "        # h2作为输入通过第三层全连接层计算得到输出结果h3\n",
    "        return x\n",
    "\n",
    "net=Net()\n",
    "# 移动模型到GPU上    # print(next(net.parameters()).device)  # 返回cuda值\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # （自己添加）\n",
    "net=net.to(device)  # 网络加载到GPU运行（自己添加）\n",
    "\n",
    "################ 输出网络结构\n",
    "# summary(net, input_size=(28*28,)) # 调用summary函数，输入模型和输入大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161daa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################优化器\n",
    "optimizer=optim.SGD(net.parameters(),lr=0.01,momentum=0.9) # 创建一个 梯度下降SGD 优化器，用来更新 net 模型的参数\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.0001)  # 基于自适应学习率的优化器，它可以根据每个参数的梯度历史动态调整学习率，从而加速收敛\n",
    "\n",
    "#####################训练\n",
    "train_loss=[]\n",
    "for epoch in range(1):  # epoch是所有数据都放入模型训练的次数\n",
    "\n",
    "    for batch_idx,(x,y) in enumerate(train_loader):  # batch_idx即iteration，表示迭代次数\n",
    "\n",
    "        # x: [b, 1, 28, 28], y: [512]\n",
    "        # [b, 1, 28, 28] => [b, 784]\n",
    "        x=x.to(device)  \n",
    "        y=y.to(device) \n",
    "        x=x.view(x.size(0),28 * 28)\n",
    "        # => [b, 10]\n",
    "        out=net(x)\n",
    "        y_onehot=one_hot(y)\n",
    "        # loss = mse(out, y_onehot)\n",
    "        # loss=F.mse_loss(out,y_onehot)  # 均方误差\n",
    "        loss_func=torch.nn.CrossEntropyLoss()  # 直接使用pytorch内置的交叉熵损失函数 \n",
    "        loss=loss_func(out,y_onehot)  # 直接使用pytorch内置的交叉熵损失函数 \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # w' = w - lr*grad\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        if batch_idx % 10==0:\n",
    "            print('epoch:',epoch,'迭代次数:',batch_idx,'loss:',loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8e55ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############输出训练准确度###############\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # （自己添加）\n",
    "train_correct = 0\n",
    "total = 0\n",
    "for data in train_loader:\n",
    "        x, y = data\n",
    "        x=x.to(device)  \n",
    "        y=y.to(device)  \n",
    "        x=x.view(x.size(0),28 * 28)\n",
    "        out = net(x)\n",
    "        pred=out.argmax(dim=1)\n",
    "        correct=pred.eq(y).sum().float().item()\n",
    "        train_correct +=correct\n",
    "        total += y.size(0)\n",
    "        train_acc=train_correct / total\n",
    "print('epoch:',epoch,'迭代次数:',batch_idx,'loss:',loss.item(),'Train accuracy:',train_acc)\n",
    "\n",
    "\n",
    "plot_curve(train_loss)  #输出loss变化曲线图\n",
    "#plt.show()   # 显示视图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775321b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 测试（利用测试数据）\n",
    "total_correct=0\n",
    "for x,y in test_loader:\n",
    "    x=x.to(device)  \n",
    "    y=y.to(device) \n",
    "    x=x.view(x.size(0),28 * 28)\n",
    "    out=net(x)\n",
    "    # out: [b, 10] => pred: [b]\n",
    "    pred=out.argmax(dim=1)\n",
    "    correct=pred.eq(y).sum().float().item()\n",
    "    total_correct+=correct\n",
    "\n",
    "total_num=len(test_loader.dataset)\n",
    "acc=total_correct / total_num\n",
    "print('Test accuracy:',acc)\n",
    "\n",
    "x,y=next(iter(test_loader))\n",
    "x=x.to(device)   # （自己添加）\n",
    "# y=y.cuda()  # （自己添加）\n",
    "out=net(x.view(x.size(0),28 * 28))\n",
    "pred=out.argmax(dim=1)\n",
    "pred=pred.to(device).data.cpu()  # 自己添加\n",
    "x=x.to(device).data.cpu()  # 自己添加\n",
    "plot_image(x,pred,'test')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a65a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################模型保存 保存整个网络\n",
    "# torch.save(net, './Regression_model_.pt')\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'Testacc': acc,\n",
    "            'TrainAcc': train_acc,\n",
    "            'Batchsize': batch_size,\n",
    "            }, f\"model_Batchsize{batch_size}_epoch{epoch}_TrainAcc{train_acc:.3f}_TestAcc{acc:.3f}.pth\")\n",
    "# #读取\n",
    "# use_model = torch.load('./Train_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
